{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HNUE5fXIb-W"
   },
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyd/anaconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"twitter_training.csv\", names=['Tweet ID', 'Borderlands entity', 'Sentiment', 'Tweet content'])\n",
    "df_dev = pd.read_csv(\"twitter_validation.csv\", names=['Tweet ID', 'Borderlands entity', 'Sentiment', 'Tweet content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Borderlands entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID Borderlands entity Sentiment  \\\n",
       "0          2401        Borderlands  Positive   \n",
       "1          2401        Borderlands  Positive   \n",
       "2          2401        Borderlands  Positive   \n",
       "3          2401        Borderlands  Positive   \n",
       "4          2401        Borderlands  Positive   \n",
       "...         ...                ...       ...   \n",
       "74677      9200             Nvidia  Positive   \n",
       "74678      9200             Nvidia  Positive   \n",
       "74679      9200             Nvidia  Positive   \n",
       "74680      9200             Nvidia  Positive   \n",
       "74681      9200             Nvidia  Positive   \n",
       "\n",
       "                                           Tweet content  \n",
       "0      im getting on borderlands and i will murder yo...  \n",
       "1      I am coming to the borders and I will kill you...  \n",
       "2      im getting on borderlands and i will kill you ...  \n",
       "3      im coming on borderlands and i will murder you...  \n",
       "4      im getting on borderlands 2 and i will murder ...  \n",
       "...                                                  ...  \n",
       "74677  Just realized that the Windows partition of my...  \n",
       "74678  Just realized that my Mac window partition is ...  \n",
       "74679  Just realized the windows partition of my Mac ...  \n",
       "74680  Just realized between the windows partition of...  \n",
       "74681  Just like the windows partition of my Mac is l...  \n",
       "\n",
       "[74682 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Borderlands entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4891</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4359</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2652</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>8069</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6960</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID   Borderlands entity   Sentiment  \\\n",
       "0        3364             Facebook  Irrelevant   \n",
       "1         352               Amazon     Neutral   \n",
       "2        8312            Microsoft    Negative   \n",
       "3        4371                CS-GO    Negative   \n",
       "4        4433               Google     Neutral   \n",
       "..        ...                  ...         ...   \n",
       "995      4891  GrandTheftAuto(GTA)  Irrelevant   \n",
       "996      4359                CS-GO  Irrelevant   \n",
       "997      2652          Borderlands    Positive   \n",
       "998      8069            Microsoft    Positive   \n",
       "999      6960      johnson&johnson     Neutral   \n",
       "\n",
       "                                         Tweet content  \n",
       "0    I mentioned on Facebook that I was struggling ...  \n",
       "1    BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "2    @Microsoft Why do I pay for WORD when it funct...  \n",
       "3    CSGO matchmaking is so full of closet hacking,...  \n",
       "4    Now the President is slapping Americans in the...  \n",
       "..                                                 ...  \n",
       "995  ⭐️ Toronto is the arts and culture capital of ...  \n",
       "996  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...  \n",
       "997  Today sucked so it’s time to drink wine n play...  \n",
       "998  Bought a fraction of Microsoft today. Small wins.  \n",
       "999  Johnson & Johnson to stop selling talc baby po...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "U2HyJRvG5trP",
    "outputId": "e01ac8ee-cacd-4fcb-921d-21074d9874dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train[['Tweet content','Sentiment']]\n",
    "df_dev = df_dev[['Tweet content','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Neutral', 'Negative', 'Irrelevant'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Irrelevant', 'Neutral', 'Negative', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=len(df_train.Sentiment.unique())\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=len(df_dev.Sentiment.unique())\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping = {'Positive': 0, 'Neutral': 1, 'Negative': 2, 'Irrelevant': 3}\n",
    "df_train.loc[:, 'Sentiment'] = df_train['Sentiment'].map(label_mapping)\n",
    "df_dev.loc[:, 'Sentiment'] = df_dev['Sentiment'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 0], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet content</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Tweet content Sentiment\n",
       "0      im getting on borderlands and i will murder yo...         0\n",
       "1      I am coming to the borders and I will kill you...         0\n",
       "2      im getting on borderlands and i will kill you ...         0\n",
       "3      im coming on borderlands and i will murder you...         0\n",
       "4      im getting on borderlands 2 and i will murder ...         0\n",
       "...                                                  ...       ...\n",
       "74677  Just realized that the Windows partition of my...         0\n",
       "74678  Just realized that my Mac window partition is ...         0\n",
       "74679  Just realized the windows partition of my Mac ...         0\n",
       "74680  Just realized between the windows partition of...         0\n",
       "74681  Just like the windows partition of my Mac is l...         0\n",
       "\n",
       "[74682 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=len(label_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 .Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data, max_length):\n",
    "    tweet_contents = data['Tweet content'].astype(str).tolist()\n",
    "    print(f\"Type of 'Tweet content': {type(tweet_contents)}\")\n",
    "    assert all(isinstance(tweet, str) for tweet in tweet_contents), \"All entries in 'Tweet content' should be strings.\"\n",
    "    \n",
    "    return tokenizer(tweet_contents, truncation=True, padding=True, max_length=max_length, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'Tweet content': <class 'list'>\n",
      "Type of 'Tweet content': <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "train_data = tokenize_data(df_train, max_length)\n",
    "dev_data = tokenize_data(df_dev, max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Frezzing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "     if name.startswith(\"bert.encoder.layer.0.\"): \n",
    "        param.requires_grad = False\n",
    "        \n",
    "for name, param in model.named_parameters():\n",
    "     if name.startswith(\"bert.encoder.layer.1.\"): \n",
    "        param.requires_grad = False\n",
    "        \n",
    "for name, param in model.named_parameters():\n",
    "     if name.startswith(\"bert.encoder.layer.2.\"): \n",
    "        param.requires_grad = False\n",
    "for name, param in model.named_parameters():\n",
    "     if name.startswith(\"bert.encoder.layer.3.\"): \n",
    "        param.requires_grad = False\n",
    "        \n",
    "for name, param in model.named_parameters():\n",
    "     if name.startswith(\"bert.encoder.layer.8.\"): \n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "     if name.startswith(\"bert.encoder.layer.9.\"): \n",
    "        param.requires_grad = False        \n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "     if name.startswith(\"bert.encoder.layer.10.\"): \n",
    "        param.requires_grad = False       \n",
    "        \n",
    "for name, param in model.named_parameters():\n",
    "     if name.startswith(\"bert.encoder.layer.11.\"): \n",
    "        param.requires_grad = False               \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight True\n",
      "bert.embeddings.position_embeddings.weight True\n",
      "bert.embeddings.token_type_embeddings.weight True\n",
      "bert.embeddings.LayerNorm.weight True\n",
      "bert.embeddings.LayerNorm.bias True\n",
      "bert.encoder.layer.0.attention.self.query.weight False\n",
      "bert.encoder.layer.0.attention.self.query.bias False\n",
      "bert.encoder.layer.0.attention.self.key.weight False\n",
      "bert.encoder.layer.0.attention.self.key.bias False\n",
      "bert.encoder.layer.0.attention.self.value.weight False\n",
      "bert.encoder.layer.0.attention.self.value.bias False\n",
      "bert.encoder.layer.0.attention.output.dense.weight False\n",
      "bert.encoder.layer.0.attention.output.dense.bias False\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.0.intermediate.dense.weight False\n",
      "bert.encoder.layer.0.intermediate.dense.bias False\n",
      "bert.encoder.layer.0.output.dense.weight False\n",
      "bert.encoder.layer.0.output.dense.bias False\n",
      "bert.encoder.layer.0.output.LayerNorm.weight False\n",
      "bert.encoder.layer.0.output.LayerNorm.bias False\n",
      "bert.encoder.layer.1.attention.self.query.weight False\n",
      "bert.encoder.layer.1.attention.self.query.bias False\n",
      "bert.encoder.layer.1.attention.self.key.weight False\n",
      "bert.encoder.layer.1.attention.self.key.bias False\n",
      "bert.encoder.layer.1.attention.self.value.weight False\n",
      "bert.encoder.layer.1.attention.self.value.bias False\n",
      "bert.encoder.layer.1.attention.output.dense.weight False\n",
      "bert.encoder.layer.1.attention.output.dense.bias False\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.1.intermediate.dense.weight False\n",
      "bert.encoder.layer.1.intermediate.dense.bias False\n",
      "bert.encoder.layer.1.output.dense.weight False\n",
      "bert.encoder.layer.1.output.dense.bias False\n",
      "bert.encoder.layer.1.output.LayerNorm.weight False\n",
      "bert.encoder.layer.1.output.LayerNorm.bias False\n",
      "bert.encoder.layer.2.attention.self.query.weight False\n",
      "bert.encoder.layer.2.attention.self.query.bias False\n",
      "bert.encoder.layer.2.attention.self.key.weight False\n",
      "bert.encoder.layer.2.attention.self.key.bias False\n",
      "bert.encoder.layer.2.attention.self.value.weight False\n",
      "bert.encoder.layer.2.attention.self.value.bias False\n",
      "bert.encoder.layer.2.attention.output.dense.weight False\n",
      "bert.encoder.layer.2.attention.output.dense.bias False\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.2.intermediate.dense.weight False\n",
      "bert.encoder.layer.2.intermediate.dense.bias False\n",
      "bert.encoder.layer.2.output.dense.weight False\n",
      "bert.encoder.layer.2.output.dense.bias False\n",
      "bert.encoder.layer.2.output.LayerNorm.weight False\n",
      "bert.encoder.layer.2.output.LayerNorm.bias False\n",
      "bert.encoder.layer.3.attention.self.query.weight False\n",
      "bert.encoder.layer.3.attention.self.query.bias False\n",
      "bert.encoder.layer.3.attention.self.key.weight False\n",
      "bert.encoder.layer.3.attention.self.key.bias False\n",
      "bert.encoder.layer.3.attention.self.value.weight False\n",
      "bert.encoder.layer.3.attention.self.value.bias False\n",
      "bert.encoder.layer.3.attention.output.dense.weight False\n",
      "bert.encoder.layer.3.attention.output.dense.bias False\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.3.intermediate.dense.weight False\n",
      "bert.encoder.layer.3.intermediate.dense.bias False\n",
      "bert.encoder.layer.3.output.dense.weight False\n",
      "bert.encoder.layer.3.output.dense.bias False\n",
      "bert.encoder.layer.3.output.LayerNorm.weight False\n",
      "bert.encoder.layer.3.output.LayerNorm.bias False\n",
      "bert.encoder.layer.4.attention.self.query.weight True\n",
      "bert.encoder.layer.4.attention.self.query.bias True\n",
      "bert.encoder.layer.4.attention.self.key.weight True\n",
      "bert.encoder.layer.4.attention.self.key.bias True\n",
      "bert.encoder.layer.4.attention.self.value.weight True\n",
      "bert.encoder.layer.4.attention.self.value.bias True\n",
      "bert.encoder.layer.4.attention.output.dense.weight True\n",
      "bert.encoder.layer.4.attention.output.dense.bias True\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.4.intermediate.dense.weight True\n",
      "bert.encoder.layer.4.intermediate.dense.bias True\n",
      "bert.encoder.layer.4.output.dense.weight True\n",
      "bert.encoder.layer.4.output.dense.bias True\n",
      "bert.encoder.layer.4.output.LayerNorm.weight True\n",
      "bert.encoder.layer.4.output.LayerNorm.bias True\n",
      "bert.encoder.layer.5.attention.self.query.weight True\n",
      "bert.encoder.layer.5.attention.self.query.bias True\n",
      "bert.encoder.layer.5.attention.self.key.weight True\n",
      "bert.encoder.layer.5.attention.self.key.bias True\n",
      "bert.encoder.layer.5.attention.self.value.weight True\n",
      "bert.encoder.layer.5.attention.self.value.bias True\n",
      "bert.encoder.layer.5.attention.output.dense.weight True\n",
      "bert.encoder.layer.5.attention.output.dense.bias True\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.5.intermediate.dense.weight True\n",
      "bert.encoder.layer.5.intermediate.dense.bias True\n",
      "bert.encoder.layer.5.output.dense.weight True\n",
      "bert.encoder.layer.5.output.dense.bias True\n",
      "bert.encoder.layer.5.output.LayerNorm.weight True\n",
      "bert.encoder.layer.5.output.LayerNorm.bias True\n",
      "bert.encoder.layer.6.attention.self.query.weight True\n",
      "bert.encoder.layer.6.attention.self.query.bias True\n",
      "bert.encoder.layer.6.attention.self.key.weight True\n",
      "bert.encoder.layer.6.attention.self.key.bias True\n",
      "bert.encoder.layer.6.attention.self.value.weight True\n",
      "bert.encoder.layer.6.attention.self.value.bias True\n",
      "bert.encoder.layer.6.attention.output.dense.weight True\n",
      "bert.encoder.layer.6.attention.output.dense.bias True\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.6.intermediate.dense.weight True\n",
      "bert.encoder.layer.6.intermediate.dense.bias True\n",
      "bert.encoder.layer.6.output.dense.weight True\n",
      "bert.encoder.layer.6.output.dense.bias True\n",
      "bert.encoder.layer.6.output.LayerNorm.weight True\n",
      "bert.encoder.layer.6.output.LayerNorm.bias True\n",
      "bert.encoder.layer.7.attention.self.query.weight True\n",
      "bert.encoder.layer.7.attention.self.query.bias True\n",
      "bert.encoder.layer.7.attention.self.key.weight True\n",
      "bert.encoder.layer.7.attention.self.key.bias True\n",
      "bert.encoder.layer.7.attention.self.value.weight True\n",
      "bert.encoder.layer.7.attention.self.value.bias True\n",
      "bert.encoder.layer.7.attention.output.dense.weight True\n",
      "bert.encoder.layer.7.attention.output.dense.bias True\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.7.intermediate.dense.weight True\n",
      "bert.encoder.layer.7.intermediate.dense.bias True\n",
      "bert.encoder.layer.7.output.dense.weight True\n",
      "bert.encoder.layer.7.output.dense.bias True\n",
      "bert.encoder.layer.7.output.LayerNorm.weight True\n",
      "bert.encoder.layer.7.output.LayerNorm.bias True\n",
      "bert.encoder.layer.8.attention.self.query.weight False\n",
      "bert.encoder.layer.8.attention.self.query.bias False\n",
      "bert.encoder.layer.8.attention.self.key.weight False\n",
      "bert.encoder.layer.8.attention.self.key.bias False\n",
      "bert.encoder.layer.8.attention.self.value.weight False\n",
      "bert.encoder.layer.8.attention.self.value.bias False\n",
      "bert.encoder.layer.8.attention.output.dense.weight False\n",
      "bert.encoder.layer.8.attention.output.dense.bias False\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.8.intermediate.dense.weight False\n",
      "bert.encoder.layer.8.intermediate.dense.bias False\n",
      "bert.encoder.layer.8.output.dense.weight False\n",
      "bert.encoder.layer.8.output.dense.bias False\n",
      "bert.encoder.layer.8.output.LayerNorm.weight False\n",
      "bert.encoder.layer.8.output.LayerNorm.bias False\n",
      "bert.encoder.layer.9.attention.self.query.weight False\n",
      "bert.encoder.layer.9.attention.self.query.bias False\n",
      "bert.encoder.layer.9.attention.self.key.weight False\n",
      "bert.encoder.layer.9.attention.self.key.bias False\n",
      "bert.encoder.layer.9.attention.self.value.weight False\n",
      "bert.encoder.layer.9.attention.self.value.bias False\n",
      "bert.encoder.layer.9.attention.output.dense.weight False\n",
      "bert.encoder.layer.9.attention.output.dense.bias False\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.9.intermediate.dense.weight False\n",
      "bert.encoder.layer.9.intermediate.dense.bias False\n",
      "bert.encoder.layer.9.output.dense.weight False\n",
      "bert.encoder.layer.9.output.dense.bias False\n",
      "bert.encoder.layer.9.output.LayerNorm.weight False\n",
      "bert.encoder.layer.9.output.LayerNorm.bias False\n",
      "bert.encoder.layer.10.attention.self.query.weight False\n",
      "bert.encoder.layer.10.attention.self.query.bias False\n",
      "bert.encoder.layer.10.attention.self.key.weight False\n",
      "bert.encoder.layer.10.attention.self.key.bias False\n",
      "bert.encoder.layer.10.attention.self.value.weight False\n",
      "bert.encoder.layer.10.attention.self.value.bias False\n",
      "bert.encoder.layer.10.attention.output.dense.weight False\n",
      "bert.encoder.layer.10.attention.output.dense.bias False\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.10.intermediate.dense.weight False\n",
      "bert.encoder.layer.10.intermediate.dense.bias False\n",
      "bert.encoder.layer.10.output.dense.weight False\n",
      "bert.encoder.layer.10.output.dense.bias False\n",
      "bert.encoder.layer.10.output.LayerNorm.weight False\n",
      "bert.encoder.layer.10.output.LayerNorm.bias False\n",
      "bert.encoder.layer.11.attention.self.query.weight False\n",
      "bert.encoder.layer.11.attention.self.query.bias False\n",
      "bert.encoder.layer.11.attention.self.key.weight False\n",
      "bert.encoder.layer.11.attention.self.key.bias False\n",
      "bert.encoder.layer.11.attention.self.value.weight False\n",
      "bert.encoder.layer.11.attention.self.value.bias False\n",
      "bert.encoder.layer.11.attention.output.dense.weight False\n",
      "bert.encoder.layer.11.attention.output.dense.bias False\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight False\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias False\n",
      "bert.encoder.layer.11.intermediate.dense.weight False\n",
      "bert.encoder.layer.11.intermediate.dense.bias False\n",
      "bert.encoder.layer.11.output.dense.weight False\n",
      "bert.encoder.layer.11.output.dense.bias False\n",
      "bert.encoder.layer.11.output.LayerNorm.weight False\n",
      "bert.encoder.layer.11.output.LayerNorm.bias False\n",
      "bert.pooler.dense.weight True\n",
      "bert.pooler.dense.bias True\n",
      "classifier.weight True\n",
      "classifier.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "     print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6  .Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(df_train['Sentiment'].tolist(), dtype=torch.long)\n",
    "dev_labels = torch.tensor(df_dev['Sentiment'].tolist(), dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx].clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TweetDataset(train_data, train_labels)\n",
    "dev_dataset = TweetDataset(dev_data, dev_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Set up the training arguments and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment_model\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    compute_metrics=lambda p: {\n",
    "        'accuracy': accuracy_score(p.predictions.argmax(axis=1), p.label_ids),\n",
    "        'precision': precision_score(p.predictions.argmax(axis=1), p.label_ids, average='weighted'),\n",
    "        'recall': recall_score(p.predictions.argmax(axis=1), p.label_ids, average='weighted'),\n",
    "        'f1': f1_score(p.predictions.argmax(axis=1), p.label_ids, average='weighted'),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28008' max='28008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28008/28008 55:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.069900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.920700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.828100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.766900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.759800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.729700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.695700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.683900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.598100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.543000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.409900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.402900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.374400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.389600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.372200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.355900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.235900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.197400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.184300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.177100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.203100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.187300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.175700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.179500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=28008, training_loss=0.4730204825242463, metrics={'train_runtime': 3324.9744, 'train_samples_per_second': 67.383, 'train_steps_per_second': 8.424, 'total_flos': 1.4737509516847104e+16, 'train_loss': 0.4730204825242463, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 01:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21273788809776306, 'eval_accuracy': 0.965, 'eval_precision': 0.9653957009474403, 'eval_recall': 0.965, 'eval_f1': 0.9650327922077923, 'eval_runtime': 4.1501, 'eval_samples_per_second': 240.959, 'eval_steps_per_second': 30.12, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21273788809776306, 'eval_accuracy': 0.965, 'eval_precision': 0.9653957009474403, 'eval_recall': 0.965, 'eval_f1': 0.9650327922077923, 'eval_runtime': 4.1501, 'eval_samples_per_second': 240.959, 'eval_steps_per_second': 30.12, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FineTune BERT Model: Youtube.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
